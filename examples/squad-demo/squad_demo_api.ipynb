{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuAD FAISS Demo - Python API\n",
    "\n",
    "This notebook demonstrates the **complete RAGDiff v2.0 workflow** using the Python API, from data preparation to comparison.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example compares two FAISS-based RAG systems using different embedding models:\n",
    "\n",
    "1. **faiss-small**: `paraphrase-MiniLM-L3-v2` (17MB, 3 layers, fast)\n",
    "2. **faiss-large**: `all-MiniLM-L12-v2` (120MB, 12 layers, more accurate)\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "**Part 1: Data Preparation**\n",
    "- Download and prepare the SQuAD dataset\n",
    "- Build FAISS indices with different embedding models\n",
    "- Generate query sets\n",
    "\n",
    "**Part 2: RAGDiff API Usage**\n",
    "- Execute queries against providers programmatically\n",
    "- Compare results using LLM evaluation\n",
    "- Analyze and export results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Preparation\n",
    "\n",
    "First, we'll set up the demo data. This only needs to be run once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**IMPORTANT: This notebook must be run from the `examples/squad-demo/` directory.**\n",
    "\n",
    "Before running this notebook, ensure you have a uv environment set up:\n",
    "\n",
    "```bash\n",
    "# Navigate to the squad-demo directory\n",
    "cd examples/squad-demo/\n",
    "\n",
    "# Create virtual environment (if not already created in project root)\n",
    "cd ../.. && uv venv && cd examples/squad-demo/\n",
    "\n",
    "# Activate the environment\n",
    "source ../../.venv/bin/activate  # On macOS/Linux\n",
    "# or\n",
    "..\\..\\..venv\\Scripts\\activate  # On Windows\n",
    "\n",
    "# Install RAGDiff in editable mode (from project root)\n",
    "cd ../.. && uv pip install -e . && cd examples/squad-demo/\n",
    "\n",
    "# Start Jupyter from the squad-demo directory\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Once Jupyter is running, you can proceed with the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages with uv...\n",
      "✓ datasets already installed\n",
      "Installing faiss-cpu...\n",
      "✓ faiss-cpu installed\n",
      "✓ sentence-transformers already installed\n",
      "✓ numpy already installed\n",
      "\n",
      "All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages using uv\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    \"datasets\",  # HuggingFace datasets for SQuAD\n",
    "    \"faiss-cpu\",  # FAISS for vector search\n",
    "    \"sentence-transformers\",  # Embedding models\n",
    "    \"numpy\",  # Numerical operations\n",
    "]\n",
    "\n",
    "print(\"Installing required packages with uv...\")\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"✓ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([\"uv\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"✓ {package} installed\")\n",
    "\n",
    "print(\"\\nAll dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download and Prepare SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data already prepared at data/\n",
      "  - 1204 documents\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Set up paths - notebook should be run from examples/squad-demo/\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = data_dir / \"documents.jsonl\"\n",
    "raw_file = data_dir / \"squad_raw.json\"\n",
    "\n",
    "# Check if already prepared\n",
    "if output_file.exists() and raw_file.exists():\n",
    "    print(f\"✓ Data already prepared at {data_dir}/\")\n",
    "    with open(output_file) as f:\n",
    "        num_docs = sum(1 for _ in f)\n",
    "    print(f\"  - {num_docs} documents\")\n",
    "else:\n",
    "    print(\"Loading SQuAD v2.0 dataset from HuggingFace...\")\n",
    "    dataset = load_dataset(\"squad_v2\", split=\"validation\")\n",
    "    print(f\"Loaded {len(dataset)} examples\")\n",
    "\n",
    "    # Extract unique contexts\n",
    "    print(\"Extracting unique context paragraphs...\")\n",
    "    contexts_seen = set()\n",
    "    documents = []\n",
    "\n",
    "    for idx, example in enumerate(dataset):\n",
    "        context = example[\"context\"]\n",
    "        if context in contexts_seen:\n",
    "            continue\n",
    "        contexts_seen.add(context)\n",
    "\n",
    "        documents.append(\n",
    "            {\n",
    "                \"id\": f\"squad_{len(documents)}\",\n",
    "                \"text\": context,\n",
    "                \"source\": \"SQuAD v2.0\",\n",
    "                \"metadata\": {\n",
    "                    \"title\": example.get(\"title\", \"Unknown\"),\n",
    "                    \"original_index\": idx,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(f\"Found {len(documents)} unique context paragraphs\")\n",
    "\n",
    "    # Write documents\n",
    "    print(f\"Writing documents to {output_file}...\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for doc in documents:\n",
    "            f.write(json.dumps(doc, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    # Save raw dataset for query generation\n",
    "    print(f\"Saving raw dataset to {raw_file}...\")\n",
    "    raw_data = {\n",
    "        \"examples\": [\n",
    "            {\n",
    "                \"id\": ex[\"id\"],\n",
    "                \"question\": ex[\"question\"],\n",
    "                \"context\": ex[\"context\"],\n",
    "                \"answers\": ex[\"answers\"],\n",
    "                \"title\": ex.get(\"title\", \"Unknown\"),\n",
    "            }\n",
    "            for ex in dataset\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(raw_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(raw_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"\\n✓ Dataset preparation complete!\")\n",
    "    print(f\"  Documents: {len(documents)}\")\n",
    "    print(f\"  Q&A pairs: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build FAISS Indices\n",
    "\n",
    "Build two FAISS indices with different embedding models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loaded 1204 documents\n",
      "\n",
      "✓ Small model index already exists at data/faiss_small.index\n",
      "\n",
      "✓ Large model index already exists at data/faiss_large.index\n",
      "\n",
      "✓ All FAISS indices ready!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Use paths relative to examples/squad-demo/\n",
    "data_dir = Path(\"data\")\n",
    "documents_file = data_dir / \"documents.jsonl\"\n",
    "\n",
    "# Load documents\n",
    "print(\"Loading documents...\")\n",
    "documents = []\n",
    "with open(documents_file, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        documents.append(json.loads(line.strip()))\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "texts = [doc[\"text\"] for doc in documents]\n",
    "\n",
    "# Build small model index (fast but less accurate)\n",
    "small_index_file = data_dir / \"faiss_small.index\"\n",
    "if small_index_file.exists():\n",
    "    print(f\"\\n✓ Small model index already exists at {small_index_file}\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Building FAISS index with SMALL model (paraphrase-MiniLM-L3-v2)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"Loading embedding model (small/fast)...\")\n",
    "    model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n",
    "\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = model.encode(\n",
    "        texts, show_progress_bar=True, batch_size=32, convert_to_numpy=True\n",
    "    )\n",
    "    embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "\n",
    "    print(\n",
    "        f\"Generated {len(embeddings)} embeddings with dimension {embeddings.shape[1]}\"\n",
    "    )\n",
    "\n",
    "    print(\"Building FAISS index with L2 distance...\")\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "\n",
    "    print(f\"Saving index to {small_index_file}...\")\n",
    "    faiss.write_index(index, str(small_index_file))\n",
    "\n",
    "    print(f\"✓ Small model index created ({index.ntotal} vectors, {index.d} dims)\")\n",
    "    print(\"  - 17MB model, 3 layers, fast but less accurate\")\n",
    "\n",
    "# Build large model index (slower but more accurate)\n",
    "large_index_file = data_dir / \"faiss_large.index\"\n",
    "if large_index_file.exists():\n",
    "    print(f\"\\n✓ Large model index already exists at {large_index_file}\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Building FAISS index with LARGE model (all-MiniLM-L12-v2)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"Loading embedding model (larger/better quality)...\")\n",
    "    model = SentenceTransformer(\"all-MiniLM-L12-v2\")\n",
    "\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = model.encode(\n",
    "        texts, show_progress_bar=True, batch_size=8, convert_to_numpy=True\n",
    "    )\n",
    "    embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "\n",
    "    print(\n",
    "        f\"Generated {len(embeddings)} embeddings with dimension {embeddings.shape[1]}\"\n",
    "    )\n",
    "\n",
    "    print(\"Building FAISS index with L2 distance...\")\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "\n",
    "    print(f\"Saving index to {large_index_file}...\")\n",
    "    faiss.write_index(index, str(large_index_file))\n",
    "\n",
    "    print(f\"✓ Large model index created ({index.ntotal} vectors, {index.d} dims)\")\n",
    "    print(\"  - 120MB model, 12 layers, slower but more accurate\")\n",
    "\n",
    "print(\"\\n✓ All FAISS indices ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Query Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Query set already exists at domains/squad/query-sets/test-queries.txt\n",
      "  - 100 queries\n",
      "\n",
      "✓ Data preparation complete! Ready to use RAGDiff API.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Use paths relative to examples/squad-demo/\n",
    "data_dir = Path(\"data\")\n",
    "raw_file = data_dir / \"squad_raw.json\"\n",
    "\n",
    "query_sets_dir = Path(\"domains/squad/query-sets\")\n",
    "query_sets_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_queries_file = query_sets_dir / \"test-queries.txt\"\n",
    "\n",
    "if test_queries_file.exists():\n",
    "    with open(test_queries_file) as f:\n",
    "        num_queries = sum(1 for _ in f)\n",
    "    print(f\"✓ Query set already exists at {test_queries_file}\")\n",
    "    print(f\"  - {num_queries} queries\")\n",
    "else:\n",
    "    print(\"Generating query sets...\")\n",
    "\n",
    "    # Load raw dataset\n",
    "    with open(raw_file, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    examples = data[\"examples\"]\n",
    "\n",
    "    # Filter answerable questions\n",
    "    answerable = [ex for ex in examples if ex[\"answers\"][\"text\"]]\n",
    "    print(f\"Found {len(answerable)} answerable questions\")\n",
    "\n",
    "    # Sample 100 questions\n",
    "    random.seed(42)\n",
    "    sampled = random.sample(answerable, min(100, len(answerable)))\n",
    "\n",
    "    # Write test queries\n",
    "    with open(test_queries_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in sampled:\n",
    "            f.write(ex[\"question\"] + \"\\n\")\n",
    "\n",
    "    print(f\"✓ Created {test_queries_file} ({len(sampled)} queries)\")\n",
    "    print(\"\\nExample questions:\")\n",
    "    for i, ex in enumerate(sampled[:3], 1):\n",
    "        print(f\"  {i}. {ex['question']}\")\n",
    "\n",
    "print(\"\\n✓ Data preparation complete! Ready to use RAGDiff API.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: RAGDiff API Usage\n",
    "\n",
    "Now let's use the RAGDiff Python API to compare our providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import RAGDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwk/Development/ansari-project/ragdiff/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"MemoryCreationRequest\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Users/mwk/Development/ansari-project/ragdiff/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"BatchMemoryCreationRequest\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Users/mwk/Development/ansari-project/ragdiff/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"BatchMemoryDeletionRequest\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Users/mwk/Development/ansari-project/ragdiff/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"BatchMemoryRetrievalRequest\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Users/mwk/Development/ansari-project/ragdiff/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"EmbedderCreationRequest\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Users/mwk/Development/ansari-project/ragdiff/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"RerankerCreationRequest\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "pymongo not installed. Install with: pip install pymongo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: squad\n",
      "Domains directory: /Users/mwk/Development/ansari-project/ragdiff/examples/squad-demo/domains\n",
      "Providers: ['faiss-small', 'faiss-large']\n",
      "Query set: test-queries\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from rich.console import Console\n",
    "\n",
    "# Rich for pretty printing\n",
    "from rich.table import Table\n",
    "\n",
    "from ragdiff.comparison import compare_runs\n",
    "from ragdiff.core.loaders import load_domain, load_provider, load_query_set\n",
    "\n",
    "# RAGDiff v2.0 API\n",
    "from ragdiff.execution import execute_run\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Configuration - paths relative to examples/squad-demo/\n",
    "domain = \"squad\"  # Directory name in domains/\n",
    "domain_dir = Path(\"domains/squad\")\n",
    "domains_dir = Path(\"domains\")\n",
    "providers = [\"faiss-small\", \"faiss-large\"]\n",
    "query_set_name = \"test-queries\"\n",
    "\n",
    "print(f\"Domain: {domain}\")\n",
    "print(f\"Domains directory: {domains_dir.absolute()}\")\n",
    "print(f\"Providers: {providers}\")\n",
    "print(f\"Query set: {query_set_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Domain Configuration ===\n",
      "Name: squad\n",
      "Description: Example RAG comparison using SQuAD dataset with FAISS providers\n",
      "\n",
      "Evaluator Model: anthropic/claude-sonnet-4-5\n",
      "\n",
      "=== Provider: faiss-small ===\n",
      "Tool: faiss\n",
      "Config: {'index_path': 'data/faiss_small.index', 'documents_path': 'data/documents.jsonl', 'embedding_service': 'sentence-transformers', 'embedding_model': 'paraphrase-MiniLM-L3-v2', 'dimensions': 384}\n",
      "\n",
      "=== Provider: faiss-large ===\n",
      "Tool: faiss\n",
      "Config: {'index_path': 'data/faiss_large.index', 'documents_path': 'data/documents.jsonl', 'embedding_service': 'sentence-transformers', 'embedding_model': 'all-MiniLM-L12-v2', 'dimensions': 384}\n"
     ]
    }
   ],
   "source": [
    "# Load domain configuration\n",
    "domain_config = load_domain(domain, domains_dir)\n",
    "\n",
    "print(\"=== Domain Configuration ===\")\n",
    "print(f\"Name: {domain_config.name}\")\n",
    "print(f\"Description: {domain_config.description}\")\n",
    "print(f\"\\nEvaluator Model: {domain_config.evaluator.model}\")\n",
    "\n",
    "# Load provider configurations\n",
    "for provider_name in providers:\n",
    "    provider_config = load_provider(domain, provider_name, domains_dir)\n",
    "    print(f\"\\n=== Provider: {provider_name} ===\")\n",
    "    print(f\"Tool: {provider_config.tool}\")\n",
    "    print(f\"Config: {provider_config.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Query Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Set: test-queries\n",
      "Total queries: 100\n",
      "\n",
      "First 5 queries:\n",
      "1. Where did France focus its efforts to rebuild its empire?\n",
      "2. What protestant religions made Northern European counties safe for Huguenot immigration?\n",
      "3. BQP and QMA are examples of complexity classes most commonly associated with what type of Turing machine?\n",
      "4. What was Apple Talk\n",
      "5. What happens when bathocyroe and ocyropsis clap their lobes together?\n"
     ]
    }
   ],
   "source": [
    "queries = load_query_set(domain, query_set_name, domains_dir)\n",
    "\n",
    "print(f\"Query Set: {query_set_name}\")\n",
    "print(f\"Total queries: {len(queries.queries)}\")\n",
    "print(\"\\nFirst 5 queries:\")\n",
    "for i, query in enumerate(queries.queries[:5], 1):\n",
    "    print(f\"{i}. {query.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute Runs\n",
    "\n",
    "Execute queries against both providers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Executing run: faiss-small\n",
      "============================================================\n",
      "\n",
      "2025-10-28 11:28:12 - ragdiff.execution.executor - INFO - Starting run: domain=squad, provider=faiss-small, query_set=test-queries, concurrency=10\n",
      "2025-10-28 11:28:12 - ragdiff.execution.executor - INFO - Loaded query set with 100 queries\n",
      "2025-10-28 11:28:14 - ragdiff.providers.faiss - INFO - Initialized sentence-transformers model: paraphrase-MiniLM-L3-v2\n",
      "2025-10-28 11:28:14 - ragdiff.providers.faiss - INFO - Loaded FAISS index with 1204 vectors from data/faiss_small.index\n",
      "2025-10-28 11:28:14 - ragdiff.providers.faiss - INFO - Loaded 1204 documents from data/documents.jsonl\n",
      "2025-10-28 11:28:14 - ragdiff.providers.factory - INFO - Created provider 'faiss-small' using tool 'faiss'\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Created provider instance: FAISSProvider()\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Run 90b02b96-c6cc-4238-848f-f8fbd70010c4 status: RUNNING\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Executing 100 queries with concurrency=10\n",
      "Progress: 10/100 queries (10 ok, 0 failed)\n",
      "Progress: 20/100 queries (14 ok, 0 failed)\n",
      "Progress: 30/100 queries (29 ok, 0 failed)\n",
      "Progress: 40/100 queries (38 ok, 0 failed)\n",
      "Progress: 50/100 queries (50 ok, 0 failed)\n",
      "Progress: 60/100 queries (60 ok, 0 failed)\n",
      "Progress: 70/100 queries (70 ok, 0 failed)\n",
      "Progress: 80/100 queries (78 ok, 0 failed)\n",
      "Progress: 90/100 queries (90 ok, 0 failed)\n",
      "Progress: 100/100 queries (100 ok, 0 failed)\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Query execution complete: 100 successes, 0 failures\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Run 90b02b96-c6cc-4238-848f-f8fbd70010c4 completed: RunStatus.COMPLETED, 100 successes, 0 failures\n",
      "2025-10-28 11:28:14 - ragdiff.core.storage - INFO - Saved run 90b02b96-c6cc-4238-848f-f8fbd70010c4 to domains/squad/runs/2025-10-28/90b02b96-c6cc-4238-848f-f8fbd70010c4.json\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Saved run to domains/squad/runs/2025-10-28/90b02b96-c6cc-4238-848f-f8fbd70010c4.json\n",
      "\n",
      "✓ Run completed: faiss-small-20251028-112812\n",
      "  Status: completed\n",
      "  Successes: 100\n",
      "  Duration: 2.33s\n",
      "\n",
      "============================================================\n",
      "Executing run: faiss-large\n",
      "============================================================\n",
      "\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Starting run: domain=squad, provider=faiss-large, query_set=test-queries, concurrency=10\n",
      "2025-10-28 11:28:14 - ragdiff.execution.executor - INFO - Loaded query set with 100 queries\n",
      "2025-10-28 11:28:16 - ragdiff.providers.faiss - INFO - Initialized sentence-transformers model: all-MiniLM-L12-v2\n",
      "2025-10-28 11:28:16 - ragdiff.providers.faiss - INFO - Loaded FAISS index with 1204 vectors from data/faiss_large.index\n",
      "2025-10-28 11:28:16 - ragdiff.providers.faiss - INFO - Loaded 1204 documents from data/documents.jsonl\n",
      "2025-10-28 11:28:16 - ragdiff.providers.factory - INFO - Created provider 'faiss-large' using tool 'faiss'\n",
      "2025-10-28 11:28:16 - ragdiff.execution.executor - INFO - Created provider instance: FAISSProvider()\n",
      "2025-10-28 11:28:16 - ragdiff.execution.executor - INFO - Run c435d5db-5759-4e5e-b436-5375f452c3d2 status: RUNNING\n",
      "2025-10-28 11:28:16 - ragdiff.execution.executor - INFO - Executing 100 queries with concurrency=10\n",
      "Progress: 10/100 queries (9 ok, 0 failed)\n",
      "Progress: 20/100 queries (15 ok, 0 failed)\n",
      "Progress: 30/100 queries (30 ok, 0 failed)\n",
      "Progress: 40/100 queries (40 ok, 0 failed)\n",
      "Progress: 50/100 queries (48 ok, 0 failed)\n",
      "Progress: 60/100 queries (56 ok, 0 failed)\n",
      "Progress: 70/100 queries (66 ok, 0 failed)\n",
      "Progress: 80/100 queries (77 ok, 0 failed)\n",
      "Progress: 90/100 queries (91 ok, 0 failed)\n",
      "Progress: 100/100 queries (99 ok, 0 failed)\n",
      "2025-10-28 11:28:17 - ragdiff.execution.executor - INFO - Query execution complete: 100 successes, 0 failures\n",
      "2025-10-28 11:28:17 - ragdiff.execution.executor - INFO - Run c435d5db-5759-4e5e-b436-5375f452c3d2 completed: RunStatus.COMPLETED, 100 successes, 0 failures\n",
      "2025-10-28 11:28:17 - ragdiff.core.storage - INFO - Saved run c435d5db-5759-4e5e-b436-5375f452c3d2 to domains/squad/runs/2025-10-28/c435d5db-5759-4e5e-b436-5375f452c3d2.json\n",
      "2025-10-28 11:28:17 - ragdiff.execution.executor - INFO - Saved run to domains/squad/runs/2025-10-28/c435d5db-5759-4e5e-b436-5375f452c3d2.json\n",
      "\n",
      "✓ Run completed: faiss-large-20251028-112814\n",
      "  Status: completed\n",
      "  Successes: 100\n",
      "  Duration: 2.36s\n"
     ]
    }
   ],
   "source": [
    "def progress_callback(current, total, successes, failures):\n",
    "    \"\"\"Progress indicator\"\"\"\n",
    "    if current % 10 == 0 or current == total:\n",
    "        print(\n",
    "            f\"Progress: {current}/{total} queries ({successes} ok, {failures} failed)\"\n",
    "        )\n",
    "\n",
    "\n",
    "runs = {}\n",
    "\n",
    "for provider_name in providers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Executing run: {provider_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    run = execute_run(\n",
    "        domain=domain,\n",
    "        provider=provider_name,\n",
    "        query_set=query_set_name,\n",
    "        label=f\"{provider_name}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "        concurrency=10,\n",
    "        per_query_timeout=30.0,\n",
    "        progress_callback=progress_callback,\n",
    "        domains_dir=domains_dir,\n",
    "    )\n",
    "\n",
    "    runs[provider_name] = run\n",
    "\n",
    "    print(f\"\\n✓ Run completed: {run.label}\")\n",
    "    print(f\"  Status: {run.status.value}\")\n",
    "    print(f\"  Successes: {run.metadata.get('successes', 0)}\")\n",
    "    print(f\"  Duration: {run.metadata.get('duration_seconds', 0):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Runs\n",
    "\n",
    "Use LLM evaluation to compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Comparing runs: faiss-small vs faiss-large\n",
      "============================================================\n",
      "\n",
      "2025-10-28 11:28:28 - ragdiff.comparison.evaluator - INFO - Starting comparison: domain=squad, run_ids=[UUID('90b02b96-c6cc-4238-848f-f8fbd70010c4'), UUID('c435d5db-5759-4e5e-b436-5375f452c3d2')], model=None\n",
      "2025-10-28 11:28:28 - ragdiff.comparison.evaluator - INFO - Auto-generated label: comparison-20251028-003\n",
      "2025-10-28 11:28:28 - ragdiff.comparison.evaluator - INFO - Loaded 2 runs\n",
      "2025-10-28 11:28:28 - ragdiff.comparison.evaluator - INFO - Using evaluator: model=anthropic/claude-sonnet-4-5\n",
      "2025-10-28 11:28:28 - ragdiff.comparison.evaluator - WARNING - Unknown model prefix for 'anthropic/claude-sonnet-4-5', skipping API key validation\n",
      "2025-10-28 11:28:28 - ragdiff.comparison.evaluator - INFO - Evaluating 100 queries across 2 runs (concurrency=10)\n",
      "2025-10-28 11:28:28 - ragdiff.comparison.evaluator - INFO - Executing 100 evaluations with concurrency=10\n",
      "Progress: 10/100 evaluations (9 ok, 0 failed)\n",
      "Progress: 20/100 evaluations (20 ok, 0 failed)\n",
      "Progress: 30/100 evaluations (30 ok, 0 failed)\n",
      "Progress: 40/100 evaluations (32 ok, 0 failed)\n",
      "Progress: 50/100 evaluations (44 ok, 0 failed)\n",
      "Progress: 60/100 evaluations (55 ok, 0 failed)\n",
      "Progress: 70/100 evaluations (72 ok, 0 failed)\n",
      "Progress: 80/100 evaluations (79 ok, 0 failed)\n",
      "Progress: 90/100 evaluations (90 ok, 0 failed)\n",
      "Progress: 100/100 evaluations (100 ok, 0 failed)\n",
      "2025-10-28 11:29:51 - ragdiff.comparison.evaluator - INFO - Evaluation complete: 100 successes, 0 failures\n",
      "2025-10-28 11:29:51 - ragdiff.core.storage - INFO - Saved comparison 6ec57253-51c8-4f74-bc95-553250574d0b to domains/squad/comparisons/2025-10-28/6ec57253-51c8-4f74-bc95-553250574d0b.json\n",
      "2025-10-28 11:29:51 - ragdiff.comparison.evaluator - INFO - Saved comparison to domains/squad/comparisons/2025-10-28/6ec57253-51c8-4f74-bc95-553250574d0b.json\n",
      "\n",
      "✓ Comparison completed\n",
      "  Duration: 0.00s\n"
     ]
    }
   ],
   "source": [
    "def comparison_progress(current, total, successes, failures):\n",
    "    \"\"\"Progress indicator for comparison\"\"\"\n",
    "    if current % 10 == 0 or current == total:\n",
    "        print(\n",
    "            f\"Progress: {current}/{total} evaluations ({successes} ok, {failures} failed)\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Comparing runs: {providers[0]} vs {providers[1]}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "comparison = compare_runs(\n",
    "    domain=domain,\n",
    "    run_ids=[run.id for run in runs.values()],\n",
    "    concurrency=10,\n",
    "    progress_callback=comparison_progress,\n",
    "    domains_dir=domains_dir,\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Comparison completed\")\n",
    "print(f\"  Duration: {comparison.metadata.get('duration_seconds', 0):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "table = Table(title=\"Comparison Results\")\n",
    "table.add_column(\"Provider\", style=\"cyan\")\n",
    "table.add_column(\"Wins\", style=\"green\")\n",
    "table.add_column(\"Losses\", style=\"red\")\n",
    "table.add_column(\"Ties\", style=\"yellow\")\n",
    "table.add_column(\"Avg Score\", style=\"blue\")\n",
    "table.add_column(\"Avg Latency\", style=\"magenta\")\n",
    "\n",
    "# Calculate stats\n",
    "stats = {\n",
    "    provider: {\"wins\": 0, \"losses\": 0, \"ties\": 0, \"scores\": [], \"latencies\": []}\n",
    "    for provider in providers\n",
    "}\n",
    "\n",
    "# Map index to provider name (evaluation uses 'a' and 'b')\n",
    "provider_map = {0: providers[0], 1: providers[1]}\n",
    "\n",
    "for eval_result in comparison.evaluations:\n",
    "    winner = eval_result.evaluation.get(\"winner\")\n",
    "\n",
    "    if winner == \"tie\":\n",
    "        for provider in providers:\n",
    "            stats[provider][\"ties\"] += 1\n",
    "    elif winner == \"a\":\n",
    "        stats[providers[0]][\"wins\"] += 1\n",
    "        stats[providers[1]][\"losses\"] += 1\n",
    "    elif winner == \"b\":\n",
    "        stats[providers[1]][\"wins\"] += 1\n",
    "        stats[providers[0]][\"losses\"] += 1\n",
    "\n",
    "    # Get scores from evaluation dict (uses score_a and score_b)\n",
    "    score_a = eval_result.evaluation.get(\"score_a\", 0)\n",
    "    score_b = eval_result.evaluation.get(\"score_b\", 0)\n",
    "    stats[providers[0]][\"scores\"].append(score_a)\n",
    "    stats[providers[1]][\"scores\"].append(score_b)\n",
    "\n",
    "# Get latencies from runs (uses duration_ms not latency_ms)\n",
    "for provider, run in runs.items():\n",
    "    for result in run.results:\n",
    "        if result.duration_ms:\n",
    "            stats[provider][\"latencies\"].append(result.duration_ms)\n",
    "\n",
    "# Add rows\n",
    "for provider in providers:\n",
    "    avg_score = (\n",
    "        sum(stats[provider][\"scores\"]) / len(stats[provider][\"scores\"])\n",
    "        if stats[provider][\"scores\"]\n",
    "        else 0\n",
    "    )\n",
    "    avg_latency = (\n",
    "        sum(stats[provider][\"latencies\"]) / len(stats[provider][\"latencies\"])\n",
    "        if stats[provider][\"latencies\"]\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    table.add_row(\n",
    "        provider,\n",
    "        str(stats[provider][\"wins\"]),\n",
    "        str(stats[provider][\"losses\"]),\n",
    "        str(stats[provider][\"ties\"]),\n",
    "        f\"{avg_score:.1f}\",\n",
    "        f\"{avg_latency:.1f}ms\",\n",
    "    )\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "output_file = Path(\"comparison_results.json\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(comparison.model_dump(mode=\"json\"), f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Comparison exported to: {output_file}\")\n",
    "print(f\"  File size: {output_file.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete RAGDiff v2.0 workflow:\n",
    "\n",
    "**Part 1: Data Preparation**\n",
    "- ✓ Downloaded SQuAD dataset from HuggingFace\n",
    "- ✓ Built FAISS indices with different embedding models\n",
    "- ✓ Generated query sets for testing\n",
    "\n",
    "**Part 2: RAGDiff API**\n",
    "- ✓ Executed queries against multiple providers\n",
    "- ✓ Compared results using LLM evaluation\n",
    "- ✓ Analyzed and exported results\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- The **large model** (all-MiniLM-L12-v2) typically wins more comparisons but is slower\n",
    "- The **small model** (paraphrase-MiniLM-L3-v2) is much faster but less accurate\n",
    "- This demonstrates the classic **quality vs speed tradeoff** in embedding models\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Create custom query sets for your domain\n",
    "- Try different embedding models (e.g., all-mpnet-base-v2)\n",
    "- Adjust concurrency for faster execution\n",
    "- Experiment with different LLM evaluators\n",
    "\n",
    "For more information, see the [RAGDiff documentation](../../CLAUDE.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
